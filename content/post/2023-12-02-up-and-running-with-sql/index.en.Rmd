---
title: "Up and Running with SQL"
author: "Bongani Ncube"
date: "2023-12-02"
slug: "up-and-running-with-sql"
categories:
- sql
- databases
tags: []
subtitle: ''
summary: ''
authors: []
lastmod: "2023-12-02T09:22:22+02:00"
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---
<script src="//yihui.org/js/math-code.js" defer></script>
<!-- Just one possible MathJax CDN below. You may use others. -->
<script defer
  src="//mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

```{r setup, include = FALSE}
knitr::opts_chunk$set(cache = TRUE, 
                      echo = TRUE, 
                      message = FALSE, 
                      warning = FALSE,
                      fig.path = "static",
                      fig.height=6, 
                      fig.width = 1.777777*6,
                      fig.align='center',
                      tidy = FALSE, 
                      comment = NA, 
                      highlight = TRUE, 
                      prompt = FALSE, 
                      crop = TRUE,
                      comment = "#>",
                      collapse = TRUE)
knitr::opts_knit$set(width = 60)
library(tidyverse)
library(reshape2)
theme_set(theme_light(base_size = 16))
make_latex_decorator <- function(output, otherwise) {
  function() {
      if (knitr:::is_latex_output()) output else otherwise
  }
}
insert_pause <- make_latex_decorator(". . .", "\n")
insert_slide_break <- make_latex_decorator("----", "\n")
insert_inc_bullet <- make_latex_decorator("> *", "*")
insert_html_math <- make_latex_decorator("", "$$")
```


{{% callout note %}}

## Introduction to databases

We do realise that most of the softwares around are designed to solve a problem!. To better understand what databases are ,we need to first understand the problems that necessitated the advent of databases. The answer to this is quite obvious ! `you have some data` or `large amounts of information` that you need to store, this data could be about:

- [x] Customers
- [x] Products
- [x] Employees etc

But why worry? , we could store the data in text files or even spreadsheets or if they are documents we can just organise them in folders.... is it! . Just having data is not a good enough reason to have a database , having data is not the problem but the problem is what comes next. Below are some of the problems that a database can solve 

- [x] size of the data
- [x] ease of updating
- [x] accuracy
- [x] sensitivity
- [x] redundancy
- [x] importance

so what`s a database?

### What is a database?

A structured storage space where the data is kept in many `tables` and
organized so that the necessary information can be easily fetched,
manipulated, and summarized.

{{% /callout %}}

### tables and fields 

```{r,echo=FALSE}
knitr::include_graphics("images/gslides/table.png")
```


{{% callout note %}}
A `table` is an organized set of related data stored in a tabular form,
i.e., in rows and columns. A `field` is another term for a `column` of a
table and `record` is the other name for a `row`
{{% /callout %}}

### Relational Data

```{r ,echo=FALSE}
knitr::include_graphics("images/gslides/relations.png")
```


```{r ,echo=FALSE}
knitr::include_graphics("images/gslides/relations2.png")
```

![Relational data are related by unique identifiers](images/gslides/053.png)

{{% callout note %}}

To better understand this, let's consider a scenario were Bongani Has a
business. say I have a number of different restaurants. In one table I
might have information about these restaurants including, where they are
located and what type of food they serve. I may then have a second table
where information about health and safety inspections is stored. Each
inspection is a different row and the date of the inspection, the
inspector, and the safety rating are stored in this table. Finally, I
might have a third table. This third table contains information pulled
from an API, regarding the number of stars given to each restaurant, as
rated by people online. Each table contains different bits of
information; however, there is a common column `id` in each of the
tables. This allows the information to be linked between the tables. The
restaurant with the `id` "JJ29JJ" in the restaurant table would refer to
the same restaurant with the `id` "JJ29JJ" in the health inspections
table, and so on. The values in this `id` column are known as
`unique identifiers` because they uniquely identify each restaurant. No
two restaurants will have the same `id`, and the same restaurant will
always have the same `id`, no matter what table you're looking at. The
fact that these tables have unique identifiers connecting each table to
all the other tables makes this example what we call **relational
data**.

{{% /callout %}}

![Unique identifiers help link entries across tables](images/gslides/054.png)

### Why relational data?

Storing data in this way has a number of advantages; however, the three
most important are:

1.  Efficient Data Storage
2.  Avoids Ambiguity
3.  Privacy


### DBMS

`DDMS` stands for `Database Management System`, a software package used
to perform various operations on the data stored in a database, such as
accessing, updating, wrangling, inserting, and removing data. There are
various types of DBMS, such as relational, hierarchical, network, graph,
or object-oriented. These types are based on the way the data is
organized, structured, and stored in the system.

### RDBMS

`RDBMS` stands for `Relational Database Management System`. It's the
most common type of DBMS used for working with data stored in multiple
tables related to each other by means of shared keys. The SQL
programming language is particularly designed to interact with RDBMS.
Some examples of RDBMS are MySQL, PostgreSQL, Oracle, MariaDB, etc.


{{% callout note %}}

### SQL constraints

| constraints | Description                                                            |
|------------------------------------|------------------------------------|
| DEFAULT     | provides a default value for a column                                  |
| UNIQUE      | allows only unique values                                              |
| NOT NULL    | allows only non-null values.                                           |
| PRIMARY KEY | allows only unique and strictly non-null values (NOT NULL and UNIQUE). |
| FOREIGN KEY | provides shared keys between two and more tables                       |

{{% /callout %}}

### unique key

A column (or multiple columns) of a table to which the UNIQUE constraint was imposed to ensure unique values in that column, including a possible NULL value (the only one).

### foreign key

A column (or multiple columns) of a table to which the FOREIGN KEY constraint was imposed to link this column to the primary key in another table (or several tables). The purpose of foreign keys is to keep connected various tables of a database.

### SQL queries

A query is a piece of code written in SQL to access the data from a database or to modify the data. Correspondingly, there are two types of SQL queries: select and action queries. The first ones are used to retrieve the necessary data (this also includes limiting, grouping, ordering the data, extracting the data from multiple tables, etc.), while the second ones are used to create, add, delete, update, rename the data, etc.

### SQL comments

A human-readable clarification on what a particular piece of code does. SQL code comments can be single-line (preceded by a double dash --) or span over multiple lines (as follows: /*comment_text*/). When the SQL engine runs, it ignores code comments. The purpose of adding SQL code comments is to make the code more comprehensive for those people who will read it in the future.

### types of SQL commands (or SQL subsets) 

```{r echo=FALSE}
library(tidyverse)
df<-tribble(~Command , ~ Explanation,
            "Data Definition Language (DDL)" ,"to define and modify the structure of a database.",
"Data Manipulation Language (DML)", "to access, manipulate, and modify data in a database.",
"Data Control Language (DCL)","to control user access to the data in the database and give or, revoke privileges to a specific user or a group of users.",
"Transaction Control Language (TCL)" ,"to control transactions in a database.",
"Data Query Language (DQL)", "to perform queries on the data in a database to retrieve the necessary information from it." )
knitr::kable(df)
```

{{% callout note %}}

### creating a table

> any computer system that deals with storing data needs to have the four fundamental functions that have the ability to:

+ `C`-REATE
+ `R`-EAD
+ `U`-UPDATE
+ `D`-ELETE 

commonly pronounced as `CRUD` 

> we use the `CREATE TABLE` statement. 

```{r,eval=FALSE}
CREATE TABLE table_name (col_1 datatype,
                           col_2 datatype,
                           col_3 datatype);
```

for instance if run the following query !
```{r,eval=FALSE}
CREATE TABLE my_table (age INTERGER,
                       sex TEXT);

```

we add the values to the table using `INSERT INTO .... VALUES (....)`

```{r,eval=FALSE}
INSERT INTO my_table VALUES (34,'male');
INSERT INTO my_table VALUES (47,'female');
INSERT INTO my_table VALUES (32,'male');   
```

then call the database using `SELECT`
```{r,eval=FALSE}
SELECT * FROM my_table;
```

{{% /callout %}}

```{r,echo=FALSE}
tribble(~age ,~sex,
        34,"male",
        47,"female",
        32,"male")
```

### Querying a database
+ we will use the `Employee attrition database`
+ A *query* is a request for data from a database table (or combination of tables). 
+ Querying is an essential skill for a data scientist, since the data you need for your analyses will often live in databases.

```{r message=FALSE, warning=FALSE,echo=FALSE}
library(tidyverse)
library(odbc)
library(DBI)
library(RSQLite)
library(tvthemes)
library(ggthemes)
library(scales)


dat_new <- read_csv("./input/WA_Fn-UseC_-HR-Employee-Attrition.csv")
dat_new <- dat_new %>%
  mutate_if(is.character, as_factor) %>%
  mutate(
    EnvironmentSatisfaction = factor(EnvironmentSatisfaction, ordered = TRUE),
    StockOptionLevel = factor(StockOptionLevel, ordered = TRUE),
    JobLevel = factor(JobLevel, ordered = TRUE),
    JobInvolvement = factor(JobInvolvement, ordered = TRUE)
  ) %>%
  select(EmployeeNumber, Attrition, everything())

```

```{r,echo=FALSE}
con<-dbConnect(RSQLite::SQLite(), ":memory:")
copy_to(con,dat_new)
```


{{% callout note %}}

**`SELECT` statement**

**select all with `*`**

+ In SQL, you can select data from a table using a *SELECT* statement. For example, the following query selects the name column from the people table:
`SELECT name FROM people;`
+ you may want to select all columns from a table use `*` rather than typing all the columns

```{r,eval=FALSE}
SELECT * FROM dat_new
```

{{% /callout %}}

```{r ,echo=FALSE}
dbGetQuery(con,'SELECT * 
                FROM dat_new LIMIT 10')
```

{{% callout note %}}
**selecting a subset**

+ you can achieve this by defining the columns to be selected e.g

```{r,eval=FALSE}
SELECT col_1,col_2,col_3 
FROM my_table;
```

using the database we get

```{r,eval=FALSE}
SELECT Attrition,Department,Education 
FROM dat_new;
```
 
{{% /callout %}}

```{r ,echo=FALSE}
dbGetQuery(con,'SELECT Attrition,Department,Education 
                FROM dat_new LIMIT 10')
```


{{% callout note %}}

**select `distinct` items in SQL**

+ Often your results will include many duplicate values. If you want to select all the unique values from a column, you can use the *DISTINCT* keyword. for instance if you have the following database table:

{{% /callout %}}

```{r,echo=FALSE}
df<-tribble(~Name,~age ,~sex,
        "Bongani",34,"male",
        "Eliza",47,"female",
        "Bongani",34,"male",
        "Peter",27,"male",
        "Fadzie",19,"female")
df
```
+ we can see that `Bongani` has been recorded twice in the dataset

```{r,eval=FALSE}
SELECT DISTINCT name,age,sex 
FROM database_table
```

```{r ,echo=FALSE}
sqldf::sqldf("SELECT DISTINCT name,age,sex FROM df ")
```

{{% callout note %}}

**filtering using `WHERE` in SQL**

+ *WHERE* is a filtering clause
+ In SQL, the WHERE keyword allows you to filter based on both text and numeric values in a table. There are a few different comparison operators you can use:

- [x] _= equal_
- [x] _<> not equal_
- [x] _< less than_
- [x] _> greater than_
- [x] _<= less than or equal to_
- [x] _>= greater than or equal to_

+ You can build up your WHERE queries by combining multiple conditions with the _AND_ keyword.


```{r,eval=FALSE}
SELECT DISTINCT name,age,sex
FROM df
WHERE sex='male';
```

{{% /callout %}}

```{r ,echo=FALSE}
sqldf::sqldf("SELECT DISTINCT name,age,sex
             FROM df
             WHERE sex='male'")
```

{{% callout note %}}

**`COUNT` and `AS` alias in SQL**

+ The *COUNT* statement lets you count then returning the number of rows in one or more columns.
+ we use `AS` to rename default name 
+ `COUNT(*)` tells you how many rows are in a table

{{% /callout %}}

```{r,eval=FALSE}
SELECT COUNT(*) AS pple_count
FROM database_table;
```

```{r ,echo=FALSE}
sqldf::sqldf("SELECT COUNT(*) AS pple_count
             FROM df")
```

+ the above query calculates the number of rows in the data and finds `5 rows`
 
> we can use `COUNT(DISTINCT column)` to get the number of unique rows

```{r,eval=FALSE}
SELECT COUNT(DISTINCT name) AS unique_count
FROM database_table;
```

```{r ,echo=FALSE}
sqldf::sqldf("SELECT COUNT(DISTINCT name) AS unique_count
             FROM df;")
```
the query above will calculate rows with distinct names and finds them to be 4

**We can use `COUNT` with `WHERE`**

+ We can do this to get the number of terms after filtering
+ how many people are male?

```{r,eval=FALSE}
SELECT COUNT(*) AS num_male
FROM database_table
WHERE sex='male';
```

```{r ,echo=FALSE}
sqldf::sqldf("SELECT COUNT(*) AS num_male
           FROM df
           WHERE sex='male'")
```

{{% callout note %}}

## Manipulating and Aggregating

```{r,echo=FALSE}
library(tidyverse)
library(odbc)
library(DBI)
library(RSQLite)
## read in the dataset
df <- readr::read_csv("recipe_site_traffic_2212.csv")

## sample 100 observations and select first 3 variables
set.seed(1123)
data1<- df |>
  sample_n(size=25) |> 
  select(1,2,3,6)

## sample 100 observations and select subsequent 3 variables(including the first(ID))
## 
set.seed(1123)
data2<- df |>
  sample_n(size=25) |> 
  select(1,2,4,5,6)
```

## Create a database for the exercises

```{r}
con<-dbConnect(RSQLite::SQLite(), ":memory:")
copy_to(con,data1)
copy_to(con,data2)
```

### filtering using `WHERE` in SQL

> the following points were outlined previously

+ *WHERE* is a filtering clause
+ In SQL, the WHERE keyword allows you to filter based on both text and numeric values in a table. There are a few different comparison operators you can use:

+ _= equal_
+ _<> not equal_
+ _< less than_
+ _> greater than_
+ _<= less than or equal to_
+ _>= greater than or equal to_

+ You can build up your WHERE queries by combining multiple conditions with the _AND_ keyword.

{{% /callout %}}

```{sql connection=con}
SELECT * 
FROM data2 
WHERE category='Potato'
```


## filtering using `IN` and `WHERE` in SQL

```{sql connection=con}
SELECT * 
FROM data2 
WHERE category IN ('Chicken','Chicken Breast')
```

{{% callout note %}}

### `COUNT` and `AS` alias in SQL

+ The *COUNT* statement lets you count then returning the number of rows in one or more columns.
+ we use `AS` to rename default name 
+ `COUNT(*)` tells you how many rows are in a table
{{% /callout %}}

```{sql connection=con}
SELECT COUNT(*) AS n 
FROM data2
```

### count filters in SQL

```{sql connection=con}
SELECT COUNT(category) AS n_potato
FROM data2 
WHERE category IN ('Chicken Breast','Chicken')
```

### Updating a database using `dbExecute`

+ categories before

```{r,echo=FALSE}
data2 |> 
  janitor::tabyl(category)
```

### Updating a database

+ we need to change a category called `Breakfast` to `Breakfast meal`
+ we shall use `REPLACE`

```{sql connection=con}
UPDATE data2 
SET category= REPLACE(category,'Breakfast','Breakfast meal')
WHERE category='Breakfast'
```

### Querying to check results

```{sql connection=con}
SELECT category, COUNT(category) as n_per_category
FROM data2
GROUP BY category
```

+ we see that `Breakfast` has updated to `Breakfast meal`

{{% callout note %}}

### Missing data in SQL

+ in SQL, `NULL` represents a missing or unknown value. You can check for NULL values using the expression IS NULL
+ Use `IS NULL` AND `IS NOT NULL`

{{% /callout %}}

*filtering missing data*

```{sql connection=con}
SELECT * 
FROM data2 
WHERE Protein IS NULL
```

*filtering nonmissing data*

```{sql connection=con}
SELECT * 
FROM data2 
WHERE Protein IS NOT NULL
```

## How many categories do we have

{{% callout note %}}

### select `distinct` items in SQL

+ Often your results will include many duplicate values. If you want to select all the unique values from a column, you can use the *DISTINCT* keyword.
{{% /callout %}}

```{sql connection=con}
SELECT COUNT(DISTINCT category) AS unique_categories 
FROM data2
```

# Advanced filters
### filtering in SQL

```{sql connection=con}
SELECT * 
FROM data2 WHERE sugar > 1 AND sugar < 5 
AND category='Breakfast meal'
```


+ also achieved by using `BETWEEN` and `AND`

```{sql connection=con}
SELECT * 
FROM data2 
WHERE sugar BETWEEN 1 AND 5 
AND category='Breakfast meal'
```

{{% callout note %}}

### filtering text data in SQL

+ use `LIKE`
+ the `LIKE` operator can be used in a WHERE clause to search for a pattern in a column. 
+ To accomplish this, you use something called a wildcard as a placeholder for some other values. There are two wildcards you can use with LIKE:

> The `%` wildcard will match zero, one, or many characters in text

> The `_` wildcard will match a single character

{{% /callout %}}

```{sql connection=con}
SELECT * 
FROM data2 
WHERE category LIKE 'Chicken%'
```

### Aggregate functions in SQL

```{sql connection=con}
SELECT AVG(sugar) AS avg_sugar,
       MAX(sugar) AS max_sugar,
       MIN(sugar) AS min_sugar,
       VARIANCE(sugar) AS variance,
       STDEV(sugar) AS stnd_deviation
FROM data2;
```

### Grouping and aggregating in SQL

```{sql connection=con}
SELECT category,AVG(sugar) AS avg_sugar,
                       MAX(sugar) AS max_sugar,
                       MIN(sugar) AS min_sugar
FROM data2
GROUP BY category;
```

> we can order the data by a certain column using `ORDER BY` clause

```{sql connection=con}
SELECT category,AVG(sugar) AS avg_sugar,
                       MAX(sugar) AS max_sugar,
                       MIN(sugar) AS min_sugar
FROM data2
GROUP BY category
ORDER BY avg_sugar;
```

> the above output shows results arranged in ascending order of `avg_sugar` , if we needed to begin with the largest descending we could use`ORDER BY...DESC`

```{sql connection=con}
SELECT category,AVG(sugar) AS avg_sugar,
                       MAX(sugar) AS max_sugar,
                       MIN(sugar) AS min_sugar
FROM data2
GROUP BY category
ORDER BY avg_sugar DESC;
```

### Using `UPPER()`

> Sometimes you may want to change a column to all upper cases

```{sql connection=con}
SELECT recipe,category , UPPER(category) AS upper_cat
FROM data2;
```

## Basic arithmetic

+ In addition to using aggregate functions, you can perform basic arithmetic with symbols like `+, -, *, and /`.
+ lets create weird variables here

```{sql connection=con}
SELECT category,(sugar-protein) AS diff_sugar_protein 
FROM data2;
```

{{% callout note %}}

## `CASE` statements

> this contains a `WHEN,THEN` and `ELSE` statement ,finished with `END`

### Take the stair `CASE`

+ using `CASE WHEN` to categorise or group data as follows
+ `SELECT`....
+ `CASE WHEN` *condition* `THEN` *category*
+ `WHEN` *condition* `THEN` *category*
+ .........................................
+ `ELSE` *some_category*
+ `END AS` *variable name*

{{% /callout %}}


```{sql connection=con}
SELECT recipe , sugar,
   CASE WHEN sugar BETWEEN 0 AND 50 THEN '0-50'
        WHEN sugar BETWEEN 51 AND 100 THEN '51-100'
        WHEN sugar BETWEEN 101 AND 200 THEN '101-200'
        WHEN sugar IS NULL THEN 'missing'
        ELSE '>200'
        END AS sugar_category
FROM data2;
```


> we can letter perform aggregations on the new column for instance get the count per each category

```{sql connection=con}
SELECT COUNT(*) AS count_per_category,
   CASE WHEN sugar BETWEEN 0 AND 50 THEN '0-50'
        WHEN sugar BETWEEN 51 AND 100 THEN '51-100'
        WHEN sugar BETWEEN 101 AND 200 THEN '101-200'
        WHEN sugar IS NULL THEN 'missing'
        ELSE '>200'
        END AS sugar_category
FROM data2
GROUP BY sugar_category;
```



{{% callout note %}}

### SQL subqueries

> A subquery is a query nested in another query and is useful for intermediate transformations

```{r,eval=FALSE}
SELECT column
FROM (SELECT column 
      FROM table) AS subquery;
```

> subqueries can be found anywhere within `SELECT,FROM,WHERE,GROUP BY`

#### use cases

- [x] comparing groups to summarised values
- [x] Reshaping Data
- [x] Combining data that cannot be joined

> for instance

+ use data1 and data2 databases for this task
+ the following is just an example and calories in data2 and data1 are the same so the result is the same
{{% /callout %}}


```{sql connection=con}
SELECT recipe,calories
FROM data2 
WHERE calories > 
      (SELECT AVG(calories) FROM data1);
```

{{% callout note %}}

### Summarize group statistics using subqueries

Sometimes you want to understand how a value varies across groups. For example, how does the maximum value per group vary across groups?

To find out, first summarize by group, and then compute summary statistics of the group results. One way to do this is to compute group values in a subquery, and then summarize the results of the subquery.

> what is the standard deviation across meal cateries in the maximum amount of sugar? What about the mean, min, and max of the maximums as well?

> Start by writing a subquery to compute the `max()`  per categoy; alias the subquery result as sugar_max. Then compute the standard deviation of sugar_max with `stddev()`.
Compute the `min()`, `max()`, and `avg()` of sugar_max too.

{{% /callout %}}


```{sql connection=con}
SELECT AVG(sugar_max) AS avg_sugar,
       MAX(sugar_max) AS max_sugar,
       MIN(sugar_max) AS min_sugar,
       VARIANCE(sugar_max) AS variance,
       STDEV(sugar_max) AS stnd_deviation
FROM (SELECT MAX(sugar) AS sugar_max
      FROM data2
         -- Compute max by...
      GROUP BY category) AS max_results
```

## SQL JOINS
### setting up the data

+ to aid with illustrations , I have created some `fake datasets` to assist in explaining and these are `join_df1.csv` and `join_df2.csv` datasets
+ read in CSV files and store them as databases in R

```{r}
# read in example csv files (join_df1 and join_df2)
join_df1 <- read.csv("join_df1.csv") |> 
  dplyr::rename(A=bongi)
join_df2 <- read.csv("join_df2.csv")|> 
  dplyr::rename(A=bongi)

join<-dbConnect(RSQLite::SQLite(), ":memory:")
copy_to(join,join_df1)
copy_to(join,join_df2)
```

### join_df1

```{sql connection=join}
SELECT * FROM join_df1
```

> this data has 8 rows and 3 columns 

### join_df2

```{sql connection=join}
SELECT * FROM join_df2
```

> this has 7 rows and 2 columns

+ note that we will use the column `A` as our `unique identifier`

{{% callout note %}}

### Querying A join

> generally the following step show how a join is done in SQL

+ `SELECT` t1.comon_column1`,`t1.common_column2`,`...
+ `FROM` table1 `AS` t1
+ `<type> JOIN` table2 `AS` t2
+ `ON` t1.common_unique_column = t2.common_unique_column`;`

### Inner Join

When talking about inner joins, we are only going to keep an observation if it is found in all of the tables we're combining. Here, we're combining the tables based on the `ArtistId` column. In our dummy example, there are only two artists that are found in *both* tables. These are highlighted in green and will be the rows used to join the two tables. Then, once the inner join happens, only these artists' data will be included after the inner join.

{{% /callout %}}


```{r,echo=FALSE}
knitr::include_graphics("images/gslides/058.png")
```


when doing an `inner join`, data from any observation found in all the tables being joined are included in the output. Here, `ArtistId`s "1" and "2" are in both the `artists` and `albums` tables. Thus, those will be the only `ArtistId`s in the output from the inner join. 

And, since it's a mutating join, our new table will have information from both tables! We now have `ArtistId`, `Name`, `AlbumId`, *and* `Title` in a single table! We've joined the two tables, based on the column `ArtistId`!

```{r,echo=FALSE}
knitr::include_graphics("images/gslides/059.png")
```

### See this in `ACTION`

```{sql connection=join}
SELECT * 
FROM join_df1
INNER JOIN join_df2
USING(A)
```

> we note from the above that only `the colours` that are `common to both tables` are returned. however instead of using `USING` we can use `ON table1.columnname=table2.columnname` where `columnname` is the column that tables to be matched by and in our example this is column `A` . when using this method it is important to give each table an `ALIAS` which is a `shorthand` for our tables

```{sql connection=join}
SELECT * 
FROM join_df1 AS j1
INNER JOIN join_df2 AS j2
ON j1.A=j2.A;            
```

> looking at the table above ,we note that `column A` has been repeated twice , thus we need to only `SELECT` the `column A` From only one of our tables hence we specify the repeated columns in the `SELECT` statement using the `table.columnname` method . So in the example above `SELECT j1.A,B,C,D`
specifies that we want we want column `A` to come from table `j1` (j1.A)

```{sql connection=join}
SELECT j1.A,B,C,D 
FROM join_df1 AS j1
INNER JOIN join_df2 AS j2
ON j1.A=j2.A;
```

> great :)! , generally we can apply the same scenario to all kinds of joins

{{% callout note %}}

### left join in SQL

For a left join, all rows in the first table specified will be included in the output. Any row in the second table that is *not* in the first table will not be included. 

In our toy example this means that `ArtistID`s 1, 2, and 3 will be included in the output; however, `ArtistID` 4 will not.

```{r,echo=FALSE}
knitr::include_graphics("images/gslides/060.png")
```
 
Thus, our output will again include all the columns from both tables combined into a single table; however, for `ArtistId` 3, there will be NAs for `AlbumId` and `Title`. NAs will be filled in for any observations in the first table specified that are missing in the second table.

```{r,echo=FALSE}
knitr::include_graphics("images/gslides/061.png")
```

{{% /callout %}}

> Let us see it in ACTION

```{sql connection=join}
SELECT j1.A,B,C,D 
FROM join_df1 AS j1
LEFT JOIN join_df2 AS j2
ON j1.A=j2.A;
```

> great , we notice the `NA` values found in the last column


{{% callout note %}}

### RIGHT JOIN IN SQL

Right Join is similar to what we just discussed; however, in the output from a right join, all rows in the final table specified are included in the output. NAs will be included for any observations found in the last specified table but not in the other tables.

In our toy example, that means, information about `ArtistID`s 1, 2, and 4 will be included. 

```{r,echo=FALSE}
knitr::include_graphics("images/gslides/062.png")
```

Again, in our toy example, we see that `right join` combines the information across tables; however, in this case, `ArtistId` 4 is included, but `Name` is an NA, as this information was not in the `artists` table for this artist.

```{r,echo=FALSE}
knitr::include_graphics("images/gslides/063.png")
```

{{% /callout %}}

> Let us see a `RIGHT JOIN` in action

```{sql connection=join}
SELECT j1.A,B,C,D 
FROM join_df1 AS j1
RIGHT JOIN join_df2 AS j2
ON j1.A=j2.A;
```

> great , notice now where the `NA` is displayed

{{% callout note %}}

### full join in SQL

Finally, a full join will take every observation from every table and include it in the output.

```{r,echo=FALSE}
knitr::include_graphics("images/gslides/064.png")
```


Thus, in our toy example, this join produces five rows, including all the observations from either table. NAs are filled in when data are missing for an observation.

```{r,echo=FALSE}
knitr::include_graphics("images/gslides/065.png")
```
{{% /callout %}}

> let us see a `FULL JOIN` in ACTION

```{sql connection=join}
SELECT j1.A,B,C,D 
FROM join_df1 AS j1
FULL JOIN join_df2 AS j2
ON j1.A=j2.A;
```

{{% callout note %}}

### Window functions

+ A window function performs an aggregate-like operation on a set of query rows. 

> However, whereas an aggregate operation groups query rows into a single result row, a window function produces a result for each query row:

### Anatomy of a window function

+ `FUNCTION_NAME() OVER()`
+ `ORDER BY`
+ `PARTITION BY`
+ `ROWS/RANGE PRECEDING/FOLLOWING/UNBOUNDED`

{{% /callout %}}

### Creating a fake dataset in R

```{r}
library(tidyverse)

sales<-tribble(~ year , ~country , ~product    , ~profit ,~Own ,~Time,
                 2000 , "Finland", "Computer"  ,   1500  ,"Y"  ,"D",
                 2000 , "Finland" ,"Phone"      ,   100   ,"Y"  ,"D",
                 2001 , "Finland" ,"Phone"      ,     10  ,"N"  ,"D",
                 2000 , "India"   ,"Calculator" ,     75  ,"Y"  ,"E",
                 2000 , "India"   ,"Calculator" ,     75  ,"N"  ,"E",
                 2000 , "India"   ,"Computer"   ,   1200  ,"N"  ,"E",
                 2000 , "USA"     , "Calculator",     75  ,"Y"  ,"E",
                 2000 , "USA"     , "Computer"  ,   1500  ,"N"  ,"E",
                 2001 , "USA"     ,"Calculator" ,     50  ,"Y"  ,"E",
                 2001 , "USA"     ,"Computer"   ,   1500  ,"Y"  ,"E",
                 2001 , "USA"     ,"Computer"   ,   1200  ,"Y"  ,"D",
                 2001 , "USA"     , "TV"        ,    150  ,"Y"  ,"D",
                 2001 , "USA"     , "TV"        ,    100  ,"Y"  ,"D")
sales

```

### Load in the necessary packages

```{r message=FALSE, warning=FALSE}
library(odbc)
library(DBI)
library(RSQLite)
```


### Set up a database using the datafile

```{r}
wind<-dbConnect(RSQLite::SQLite(), ":memory:")
copy_to(wind,sales)
```

### Lets get started

+ The row for which function evaluation occurs is called the current row.
+ The query rows related to the current row over which function evaluation occurs comprise the window for the current row.

{{% callout note %}}

### `ROW_NUMBER() OVER()` 

+ use it if maybe you have duplicates or intend to create rowids for your data

{{% /callout %}}


```{sql connection=wind}
SELECT ROW_NUMBER() OVER () AS row_id , year, country, product, profit
FROM sales;
```

{{% callout note %}}

### PARTITION BY

+ This splits the table into `partitions` based on a column's unique values and results aren't rolled into one column

> therefore `ROW_NUMBER()` With `PARTITION BY` produces the row number of each row within its partition. In this case, rows are numbered per country. By default, partition rows are unordered and row numbering is nondeterministic. 

{{% /callout %}}

```{sql connection=wind}
SELECT ROW_NUMBER() OVER(PARTITION BY country) AS row_num1,
       year, country, product, profit
FROM sales;
```

> its also possible to use `ROW_NUMBER()` With `ORDER BY` to determine ranks 

```{sql connection=wind}
SELECT ROW_NUMBER() OVER(ORDER BY profit DESC) AS row_num1,
       year, country, product, profit
FROM sales;
```

> in the above example , we see that we have ranked our data according to `profits` implying that each rowid also signifies the rank of profit

{{% callout note %}}

### RANK()

+ ROW_NUMBER assigns different numbers to profits with the same amount, so it's not a useful ranking function; if profits are the same , they should have the same rank.
{{% /callout %}}

> in such a case we use `RANK()`

```{sql connection=wind}
SELECT RANK() OVER(ORDER BY profit DESC) AS RANK, 
     profit ,year, country, product
FROM sales;
```

### `DENSE_RANK()`

> we can use `DENSE_RANK()` if we need ranks to be ordered or require a further partition

```{sql connection=wind}
SELECT DENSE_RANK() OVER(PARTITION BY country ORDER BY profit DESC) AS RANK, 
     profit ,year, country, product
FROM sales;
```

> now we have ranked our profits by country starting with the highest profit in each country

{{% callout note %}}

### Aggregations

+ window functions are similar to `GROUP BY` aggregate function but all rows stay in the output
{{% /callout %}}

> using the sales information table, these two queries perform aggregate operations that produce a single global sum for all rows taken as a group, and sums grouped per country:

```{sql connection=wind}
SELECT SUM(profit) AS total_profit
FROM sales;
```


> lets us see a `GROUP BY` in action

```{sql connection=wind}
SELECT country, SUM(profit) AS country_profit
FROM sales
GROUP BY country;
```
       

> On the other hand , window operations do not collapse groups of query rows to a single output row. Instead, they produce a result for each row. Like the preceding queries, the following query uses `SUM()`, but this time as a window function:


```{sql connection=wind}
SELECT
year, country, product, profit,
         SUM(profit) OVER() AS total_profit,
         SUM(profit) OVER(PARTITION BY country) AS country_profit
FROM sales
ORDER BY country, year, product, profit;         
```
       
{{% callout note %}}

> we have included  `OVER` clause that specifies how to partition query rows into groups for processing by the window function:

+ The first OVER clause is empty, which treats the entire set of query rows as a single partition. The window function thus produces a global sum, but does so for each row.
+ The second OVER clause partitions rows by country, producing a sum per partition (per country). The function produces this sum for each partition row.

> Window functions are permitted only in the select list and `ORDER BY` clause. Query result rows are determined from the `FROM` clause, after `WHERE, GROUP BY`, and `HAVING` processing, and windowing execution occurs before `ORDER BY`, `LIMIT`, and `SELECT DISTINCT`.


### WITH CLAUSE

+ This is used to create a temporary relation such that the output of this temporary relation is available and is used by the query that is associated with the `WITH` clause. for instance the following table can be created as a temporary table 

### FRAMES

> Frames allow you to "peek" forwards or backward without first using the relative fetching functions, `LAG` and `LEAD`, to fetch previous rows' values into the current row.

#### ROWS BETWEEN

- [x] `ROWS BETWEEN [START] AND [FINISH]`
+ `n PRECEDING` : `n` rows before current row
+ `CURRENT ROW` : the current row 
+ `n FOLLOWING` : `n` rows after the current row 
{{% /callout %}}


> the following query calculates the number of sales per year and per country(i.e grouped by year and country)

```{sql connection=wind}
SELECT
    year, country, COUNT(*) AS num_sales
  FROM sales
  GROUP BY year, country;
```

like soo...

### `WITH` and a `FRAME`

+ We create a temporary table called `country_sales`

```{sql connection=wind}
WITH Country_sales AS (
  SELECT
    year, country, COUNT(*) AS num_sales
  FROM sales
  GROUP BY year, country)

SELECT
  year, country, num_sales,
  -- Calculate each country's 3s-ales moving total
  SUM(num_sales) OVER
    (PARTITION BY country
     ORDER BY year ASC
     ROWS BETWEEN
     2 PRECEDING AND CURRENT ROW) AS sales_MA
FROM Country_sales
ORDER BY country ASC, year ASC;
```




