---
title: "Data Transformation Explanatory data Analysis"
author: "Bongani Ncube"
date: "2023-09-22"
slug: "data-transformation-explanatory-data-analysis"
categories:
- datascience
- dplyr
- janitor
- munging
- Programming
tags: []
subtitle: ''
summary: ''
authors: []
lastmod: "2023-09-22T11:15:29+02:00"
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---


```{r setup, include = FALSE}
knitr::opts_chunk$set(cache = TRUE, 
                      echo = TRUE, 
                      message = FALSE, 
                      warning = FALSE,
                      fig.path = "static",
                      fig.height=6, 
                      fig.width = 1.777777*6,
                      fig.align='center',
                      tidy = FALSE, 
                      comment = NA, 
                      highlight = TRUE, 
                      prompt = FALSE, 
                      crop = TRUE,
                      comment = "#>",
                      collapse = TRUE)
knitr::opts_knit$set(width = 60)
library(tidyverse)
library(reshape2)
theme_set(theme_light(base_size = 16))
make_latex_decorator <- function(output, otherwise) {
  function() {
      if (knitr:::is_latex_output()) output else otherwise
  }
}
insert_pause <- make_latex_decorator(". . .", "\n")
insert_slide_break <- make_latex_decorator("----", "\n")
insert_inc_bullet <- make_latex_decorator("> *", "*")
insert_html_math <- make_latex_decorator("", "$$")
```

## Objectives

Welcome to yet another R blog on data analysis and wranling using R
At the end of this tutorial you will:

- [x] understand the role of data wrangling
- [x] understand the basic capabilities of **dplyr** 
- [x] acquire skills to perform common data wrangling using **dplyr,stringr,tidyr and forcats** packages

### What is data wrangling?


{{% callout note %}}
Data wrangling is also known as Data Munging or Data Transformation. It is loosely the process of manually converting or mapping data from one "raw" form into another format. The process allows for more convenient consumption of the data. Data analysts typically spend the majority of their time in the process of data wrangling compared to the actual analysis of the data.
{{% /callout %}}


![Main parts of data wrangling](datawrangle.png)


### Common data wrangling processes

The common data wrangling processes include:

{{% callout note %}}
- [x]  reducing the size of dataset by selecting certain variables (or columns)
- [x]  generating new variable from existing variables
- [x]  sorting observation of a variable
- [x]  grouping observations based on certain criteria
- [x]  reducing variables to groups in order to estimate summary statistic
{{% /callout %}}

### Use tidyverse functions for achieving this!

> already have a blog about these functions

{{% callout note %}}
- [x]  `dplyr::select()` - to select a number of variables from a dataframe
- [x]  `dplyr::mutate()` - to generate a new variable from existing variables
- [x]  `dplyr::arrange()`- to sort observation of a variable
- [x]  `dplyr::filter()` - to group observations that fulfil certain criteria
- [x]  `dplyr::group_by()` and `dplyr::summarize()` - to reduce variable to groups in order to provide summary statistic
{{% /callout %}}

### setup

```{r}
library(tidyverse)
library(lubridate)
```


```{r}
new_data <- read_csv("recipe_site_traffic_2212.csv")
dim(new_data)
names(new_data)
```

Take a peek at the recipe site dataset.

The dataset contains:

-   947 observations
-   8 variables

```{r}
glimpse(new_data)
```

Next, we examine the first five observations of the data. The rest of the observations are not shown. You can also see the types of variables:

-   `chr` (character),
-   `int` (integer),
-   `dbl` (double)

```{r}
new_data|> head(n = 5)
```


## Select variables, generate new variable and rename variable

We will work with these functions.

-   `dplyr::select()`
-   `dplyr::mutate()` and
-   `dplyr::rename()`

### Select variables using `dplyr::select()`

When you work with large datasets with many columns, it is sometimes easier to select only the necessary columns to reduce the dataset size. This is possible by creating a smaller dataset (fewer variables). Then you can work on the initial part of data analysis with this smaller dataset. This will greatly help data exploration.

{{% callout note %}}
however for this exercise we gonna need all the variables for exploration so we will select everything
{{% /callout %}}

```{r}
(new_data <- new_data|> 
  dplyr::select(everything()))
```

### extending `select` verb

{{% callout note %}}
sometimes it is necessary to perform conditional selection on variables because
+ at times you need only numerical variables for correlations
+ you may only need categorical variables for testing independence
{{% /callout %}}
> for such a case we can use functions such as `select_if`

```{r}
new_data |> select_if(is.numeric)
```
> the code above will only select variables of class `numeric`

### Generate new variable using `mutate()`

With `mutate()`, you can generate a new variable. For example, in the dataset `new_data`, we want to create a new variable named `log_calories` which is a log transformation of calories .

$$log\_calories=\log(calories)$$

And let's observe the first five observations:

```{r}
new_data <- new_data|> 
  dplyr::mutate(log_calories = log(calories))

new_data |> 
  dplyr::select(log_calories,calories,sugar,category)|> 
  slice_head(n = 5)
```

### extending `mutate` function
> it is often wise to perform conditional mutations on data 

{{% callout note %}}
sometimes it is necessary to perform conditional mutation on variables such that
+ you only mutate is a certain condition is met
{{% /callout %}}

> we often use `mutate_if()` ,`mutate_at` and `mutate_all` to achieve this

+ check data types before the coming operation
```{r}
map_chr(new_data,class)
```

+ we note that category ,servings and high_traffic are characters when in actual fact they should be 
factors
> lets change that

```{r}
## change characters to factors
new_data <- new_data |> 
  mutate_if(is.character,as.factor)

## now check the data types
map_chr(new_data,class)
```

> nice!! we have turned every `character` to a `factor`

### Rename variable using `rename()`

{{% callout note %}}
Now, we want to rename

-   variable category to `meal_category`
-   variable log_calories to `log_of_calories`
{{% /callout %}}

```{r}
(new_data <- new_data |> 
  rename(meal_category = category,
         log_of_calories = log_calories))
```

## Sorting data and selecting observation

The function `arrange()` can sort the data. And the function `filter()`allows you to select observations based on your criteria.

### Sorting data using `arrange()`

We can sort data in ascending or descending order using the `arrange()` function. 

```{r}
new_data|> 
  arrange(log_of_calories) |> 
  relocate(log_of_calories)
```


{{% callout note %}}
+ this will like arrange the data based on log_calories from smallest to biggest
+ we can arrange from biggest to smallest as well using `desc()`
{{% /callout %}}

```{r}
new_data|> 
  arrange(desc(log_of_calories)) |> 
  relocate(log_of_calories)
```

### Select observation using `filter()`

{{% callout note %}}
We use the `filter()` function to select observations based on certain criteria. Here, in this example, we will create a new dataset (which we will name as `new_data_m`) that contains observations where high_traffic is `NA` ,in this case `NA` implies low
{{% /callout %}}


```{r}
new_data_m <- new_data|> 
  filter(is.na(high_traffic)) |> 
  relocate(high_traffic)
new_data_m
```
+ we can see that we have a smaller dataset in which all high_traffic observations are `NA` Values


Next, we will create a new dataset (named `new_data_high_logless0`) that contain

-   `high_traffic=='high'` and `log_of_calories<0`

```{r}
new_data_high_logless0 <- new_data|> 
  filter(high_traffic=='High'& log_of_calories<0) |> 
  relocate(high_traffic,log_of_calories)
new_data_high_logless0
```

## Group data and get summary statistics

The`group_by()` function allows us to group data based on categorical variable. Using the `summarize` we do summary statistics for the overall data or for groups created using `group_by()` function.

### Group data using `group_by()`

The `group_by` function will prepare the data for group analysis. For example,

-   to get summary values for mean `calories`, mean `sugar` and mean `carbohydrate`
-   for category

```{r}
new_data_category <- new_data|> 
  group_by(meal_category)
```

### Summary statistic using `summarize()`

Now that we have a group data named `new_data_category`, now, we would summarize our data using the mean and standard deviation (SD) for the groups specified above.

```{r}
new_data_category|> 
  summarise(mean_calories = mean(calories, na.rm = TRUE), 
            mean_sugars  = mean(sugar, na.rm = TRUE),
            mean_carbohydrate = mean(carbohydrate, na.rm = TRUE))
```

To calculate the frequencies for two variables for the recipe dataset

-   category
-   high_traffic

```{r}
new_data|> 
  group_by(meal_category)|>
  count(high_traffic, sort = TRUE)
```

or

```{r}
new_data |> 
  count(meal_category, high_traffic, sort = TRUE)
```

## More complicated **dplyr** verbs

To be more efficient, use multiple **dplyr** functions in one line of R code. For example,

```{r filterstarwars}
new_data |> 
  filter(meal_category != "Pork", calories>10, !is.na(protein))|> 
  dplyr::select(recipe,meal_category,calories, sugar,carbohydrate,protein, high_traffic)|>
  mutate(meal_category=if_else(is.na(meal_category),"low",meal_category)) |> 
  group_by(meal_category)|>
  summarize(mean_calories = mean(calories, na.rm = TRUE), 
            mean_sugars  = mean(sugar, na.rm = TRUE),
            mean_carbohydrate = mean(carbohydrate, na.rm = TRUE),
            freq = n())
```

## Data transformation for categorical variables

### **forcats** package

Data transformation for categorical variables (factor variables) can be facilitated using the **forcats** package.

### Conversion from numeric to factor variables

{{% callout note %}}
Now, we will convert the integer (numerical) variable to a factor (categorical) variable. For example, we will generate a new factor (categorical) variable named `high_sugars` from variables `sugars`  (both double variables). We will label `high_bp`as *High* or *Not High*.

The criteria:

-   if sugar $sugar \geq 20 or is.na$  then labelled as High, else is Not High
{{% /callout %}}


```{r}
new_data <- new_data|> 
  mutate(high_sugar = if_else(sugar >= 20|is.na(sugar) ,
                           "High", "Not High"))
new_data|> count(high_sugar)
```

of by using `cut()`

```{r}
new_data <- new_data|> 
  filter(!is.na(carbohydrate)) |> 
  mutate(cat_carboydrates = cut(carbohydrate, breaks = c(-Inf, 120, 130, Inf),
                       labels = c('<120', '121-130', '>130')))
new_data|> count(cat_carboydrates)
```

```{r}
new_data|> 
  group_by(cat_carboydrates)|> 
  summarize(min_carbohydrates = min(carbohydrate),
            max_carbohydrates = max(carbohydrate))
```

### Recoding variables

We use this function to recode variables from old to new levels. For example:

```{r }
new_data <- new_data|>
  mutate(cat_carboydrates_new = recode(cat_carboydrates, "<120" = "120 or less",
                          "121-130" = "121 to 130",
                          ">130" = "131 or higher"))
new_data|> count(cat_carboydrates_new)
```

### Changing the level of categorical variable 

{{% callout note %}}
Variable `cat_carboydrates_new` will be ordered as

-   less or 120, then
-   121 - 130, then
-   131 or higher
{{% /callout %}}



```{r}
levels(new_data$cat_carboydrates_new)
new_data|> count(cat_carboydrates_new)
```

To change the order (in reverse for example), we can use `fct_relevel`. Below the first level group is sbp above 130, followed by 121 to 130 and the highest group is less than 120. 

```{r}
new_data <- new_data|>
  mutate(relevel_cat_carboydrates = fct_relevel(cat_carboydrates, ">130", "121-130", "<120"))
levels(new_data$relevel_cat_carboydrates)
new_data|> count(relevel_cat_carboydrates)
```

 




